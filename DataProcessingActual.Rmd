---
title: "R Notebook"
output:
  pdf_document:
    toc: true
    toc_depth: 2
---

## Load Libraries

```{r}
library(dewey)
library(data.table)
library(tidyverse)
library(tidync)

library(tree)
library(randomForest)
library(caret)
library(rpart.plot)
```

```{r}
# if(file.exists("source")) unlink("source", TRUE)
# if(file.exists("source-out")) unlink("source-out", TRUE)
# 
# stream_generate_test(iterations = 1)
# list.files("source")
# 
# read_folder <- stream_read_csv(sc, "source")

# spark_disconnect(sc)
```

## Load initial data

```{r}
# load the wait time files
files <-
  data.table("filePath" = grep("*\\.csv", list.files("data/"), 
                               value = TRUE)) %>%
  .[, "rideName" :=  sub("(\\_old)?\\.csv", "", filePath)] %>%
  .[, rideName :=
      toupper(ifelse(rideName == "7_dwarfs_train", "dwarfs_train", rideName))]

round_time = function(x, precision, method = round) {
  if ("POSIXct" %in% class(x) == FALSE)
    stop("x must be POSIXct")
  
  tz = attributes(x)$tzone
  secs_rounded = method(as.numeric(x) / precision) * precision
  as.POSIXct(secs_rounded, tz = tz, origin = "1970-01-01")
}

longerData <- function(x) {
  rbindlist(
    list(x %>% 
           .[, .(RIDENAME, date, datetime, SACTMIN)] %>% 
           .[, `:=`(TYPE = "SACTMIN", WAITTIME = SACTMIN, SACTMIN = NULL)],
         x %>% 
           .[, .(RIDENAME, date, datetime, SPOSTMIN)] %>% 
           .[, `:=`(TYPE = "SPOSTMIN", WAITTIME = SPOSTMIN, SPOSTMIN = NULL)],
         x %>%
           .[, .(RIDENAME, date, datetime, CLOSED)] %>%
           .[, `:=`(TYPE = "CLOSED", WAITTIME = CLOSED, CLOSED = NULL)])
    )
}

dropDuplicated <- function(x) {
  x[!duplicated(x)]
}

roundTime <- 5

dt <- unique(rbindlist(apply(files, 1, function(x) { 
    fread(paste0("data/", x["filePath"])) %>%
    .[, CLOSED := ifelse(!is.na(SPOSTMIN) & SPOSTMIN == -999, 1, 0)] %>%
    .[, SPOSTMIN := 
        ifelse(!is.na(SPOSTMIN) & SPOSTMIN == -999, NA, SPOSTMIN)] %>%
    .[, RIDENAME := x["rideName"]]
  }), use.names = TRUE)) %>%
  longerData(.) %>%
  .[, `:=`(DATE = as.ordered(as.Date(date, format = "%m/%d/%Y")),
           date = NULL,
           DATETIME = round_time(datetime, 60*roundTime, floor),
           datetime = NULL)] %>%
  .[, `:=`(MONTH = month(DATETIME),
           DAY = mday(DATETIME),
           TIME = as.ITime(DATETIME),
           DATETIME = NULL)] %>%
  .[, WAITTIME := mean(WAITTIME, na.rm = TRUE),
    by = .(RIDENAME, TYPE, DATE, MONTH, DAY, TIME)] %>%
  .[TYPE == "CLOSED", WAITTIME := 
      ifelse(!is.nan(WAITTIME) & WAITTIME != 0, 1, 0)] %>%
  dropDuplicated(.) %>%
  dcast(., DATE + MONTH + DAY + TIME ~ RIDENAME + TYPE, 
        value.var = "WAITTIME")

dt[dt == "NaN" | dt == "-Inf"] <- NA
print(dt)
```

```{r}
RIDENAME <- toupper(c("dwarfs_train", "alien_saucers", "dinosaur", 
               "expedition_everest", "flight_of_passage", "kilimanjaro_safaris", 
               "navi_river", "pirates_of_caribbean", "rock_n_rollercoaster", 
               "slinky_dog", "soarin", "spaceship_earth", "splash_mountain", 
               "toy_story_mania"))
OPENDATE <- as.Date(c("2014/05/28", "2018/06/30", "1998/04/22", "2006/04/09", 
                       "2017/05/27", "1998/04/22", "2017/05/27", "1973/12/17", 
                       "1999/07/29", "2018/06/30", "2005/05/15", "1982/10/01", 
                       "1992/07/17", "2008/05/31"))
SPLASH <- c(FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE,  FALSE, FALSE,
            FALSE, FALSE, TRUE,  FALSE)
INDOOR <- c(FALSE, FALSE, TRUE,  FALSE, TRUE, FALSE, TRUE,  TRUE,  TRUE,  FALSE,
            TRUE,  TRUE,  FALSE, TRUE)
AGEHIERARCHY <- c(10, 13,  4,  8, 11, 5, 12,  1,  6, 14, 7,  2,  3,  9)
DURATION <- c(3, 2.5, 3.5, 4, 6, 20, 5, 7.5, 1.5, 3, 8, 16, 18, 6.5)
WAITPERHUNDRED <- c(5, 10, 3, 4, 4, 4, 5, 1.5, 2.5, 5, 3, 3, 3.5, 4.5)
PARK <- toupper(c("mk", "hs", "ak", "ak", "ak", "ak", "ak", "mk", "hs", "hs", 
                  "ep", "ep", "mk", "hs"))
dtMeta <- data.table(RIDENAME, OPENDATE, AGEHIERARCHY, SPLASH, INDOOR, PARK, 
                     DURATION, WAITPERHUNDRED)
```

## Summary Statistics (Wait Times)

```{r}
dt %>%
  select(ends_with("_SACTMIN")) %>%
  `colnames<-`(., dtMeta$RIDENAME[order(dtMeta$RIDENAME)]) %>%
  filter(rowSums(!is.na(.)) != 0) %>%
  melt() %>%
  mutate(variable = factor(variable, levels = rev(unique(variable)))) %>%
  ggplot() +
  geom_vline(xintercept = 30, color = "green", size = 1) +
  geom_vline(xintercept = 60, color = "yellow", size = 1) +
  geom_vline(xintercept = 90, color = "orange", size = 1) +
  geom_vline(xintercept = 120, color = "red", size = 1) +
  xlim(c(0, 180)) +
  geom_boxplot(aes(y = variable, x = value), outlier.alpha = .2, size = .75,
               color = RColorBrewer::brewer.pal(9, "Set1")[4]) +
  labs(title = "Distribution of actual ride wait times") +
  xlab("Actual Ride Wait Time") +
  ylab("Ride")

dt %>%
  select(ends_with("_SPOSTMIN")) %>%
  `colnames<-`(., dtMeta$RIDENAME[order(dtMeta$RIDENAME)]) %>%
  filter(rowSums(!is.na(.)) != 0) %>%
  melt() %>%
  mutate(variable = factor(variable, levels = rev(unique(variable)))) %>%
  ggplot() +
  geom_vline(xintercept = 30, color = "green", size = 1) +
  geom_vline(xintercept = 60, color = "yellow", size = 1) +
  geom_vline(xintercept = 90, color = "orange", size = 1) +
  geom_vline(xintercept = 120, color = "red", size = 1) +
  xlim(c(0, 180)) +
  geom_boxplot(aes(y = variable, x = value), outlier.alpha = .2, size = .75,
               color = RColorBrewer::brewer.pal(9, "Set1")[5]) +
  labs(title = "Distribution of posted ride wait times") +
  xlab("Posted Ride Wait Time") +
  ylab("Ride")
```

```{r}
dt %>%
  select(ends_with(c("_SACTMIN", "_SPOSTMIN"))) %>%
  melt() %>%
  filter(!is.na(value)) %>%
  mutate(type = as.factor(ifelse(grepl("SACTMIN", variable), 
                                 "Actual", "Posted"))) %>%
  mutate(variable = factor(str_remove(variable, "_SACTMIN|_SPOSTMIN"), 
         levels = rev(sort(dtMeta$RIDENAME)))) %>%
  ggplot() +
  geom_vline(xintercept = 30, color = "green", size = 1) +
  geom_vline(xintercept = 60, color = "yellow", size = 1) +
  geom_vline(xintercept = 90, color = "orange", size = 1) +
  geom_vline(xintercept = 120, color = "red", size = 1) +
  xlim(c(0, 180)) +
  geom_boxplot(aes(y = variable, x = value, color = type), size = .75,
               position = "identity", outlier.alpha = .1, fill = "transparent") +
  scale_color_manual(values = RColorBrewer::brewer.pal(9, "Set1")[4:5], 
                     name = "Time Type", 
                     labels = c("Actual", "Posted")) +
  labs(title = "Distribution of posted and actual ride wait times") +
  xlab("Posted and Actual Ride Wait Time") +
  ylab("Ride") +
  theme(legend.position = "bottom")
```


### Remove Outliers 

```{r}
removeOutliers <- function(x) {
  z <- abs(x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  x <- ifelse(is.na(x) | z < 3, x, NA)
  return(x)
}

cols <- grep(paste0(dtMeta$RIDENAME, collapse = "|"), colnames(dt),
             value = TRUE)
cols <- cols[!grepl("CLOSED", cols)]
dt <- dt[, (cols) := lapply(.SD, removeOutliers), .SDcols = cols]
```

### T Test

```{r}
big <- apply(expand_grid(dtMeta$RIDENAME, c("_SACTMIN", "_SPOSTMIN")), 1, 
      function(x) {
        paste0(x, collapse = "")
      })
small <- rep(dtMeta$RIDENAME, each = 2)
names(small) <- big
ttest <- dt %>%
  select(ends_with(c("_SACTMIN", "_SPOSTMIN"))) %>%
  melt() %>%
  filter(!is.na(value)) %>%
  mutate(type = as.factor(ifelse(
    grepl("SACTMIN", variable), "Actual", "Posted")))

t.test(ttest[type == "Actual" & !is.nan(value), 
             value := log(value)][, .(value)], 
       ttest[type == "Posted" & !is.nan(value), 
             value := log(value)][, .(value)])

# ttest <- dt %>%
#   select(DATE, TIME, ends_with(c("_SACTMIN", "_SPOSTMIN"))) %>%
#   pivot_longer(cols = 3:ncol(.)) %>%
#   mutate(type = as.factor(ifelse(grepl("SACTMIN", name), 
#                                  "Actual", "Posted"))) %>%
#   mutate(name = as.factor(small[name])) %>%
#   data.table() %>%
#   dcast(DATE + TIME + name ~ type, value.var = "value",
#         fun.aggregate = function(x) { mean(x, na.rm = TRUE) }) %>%
#   filter(!is.nan(Actual) & !is.nan(Posted))
# 
# ttest <- rbindlist(lapply(unique(ttest$name), function(x) {
#   tmp <- summary(lm(Actual ~ Posted, ttest[name == x]))
#   print(tmp)
#   data.table(name = x,
#              "r2" = round(tmp$adj.r.squared, 4),
#              "interceptP" = round(tmp$coefficients[1, 4], 4),
#              "postedP" = round(tmp$coefficients[2, 4], 4))
# }))
# ttest[order(name)]
```

```{r warning=FALSE, eval=FALSE}
library(GGally)

summary(dt)

sapply(unique(dtMeta$PARK), function(x) {
  rides <- dtMeta$RIDENAME[dtMeta$PARK == x]
  cols <- (1:ncol(dt))[grepl(paste0(rides, collapse = "|"), colnames(dt))]
  print(ggpairs(dt[, ..cols], title = paste("Correlation plot for rides in", x), 
                upper = list(continuous = wrap("cor", size = 3)),
                progress = FALSE) +
          theme(text = element_text(size = 6)))
})
```


```{r, echo = FALSE, results='hide', fig.keep='all', eval=FALSE}
set.seed(1234)
rowPicker <- sample(c(TRUE, FALSE), nrow(dt), replace = TRUE, prob = c(.5, .5))
train <- dt[rowPicker, ]
test <- dt[!rowPicker, ]

lapply(unique(dtMeta$PARK), function(x) {
  # get rides that are in the same park, date, and time
  rides <- c(colnames(train)[grepl(paste0(dtMeta$RIDENAME[dtMeta$PARK == x],
                                        collapse = "|"),
                                 colnames(train))],
             "DATE", "TIME")
  # get the actual ride time variables
  actuals <- rides[grepl("(SACTMIN)", rides)]
  # return decision trees for the actual ride time variables
  return(trees <- sapply(actuals, function(y) {
    tr <- rpart(as.formula(paste(y, "~ .")), train[, ..rides])
    rpart.plot(tr, main = y)
    return(tr)
    }))
})
```

## Load and flesh out metadata

```{r}
# metadata <- unique(rbindlist(list(fread("data/metadata/metadata.csv", na.strings = c("")), 
#                                   fread("data/metadata/metadata_old.csv", na.strings = c(""))),
#                              fill = TRUE)) %>%
#   .[, DATE := as.ordered(format(as.Date(DATE, format = "%m/%d/%y")))] %>%
#   fwrite("newMetadata.csv")
metadata <- fread("data/metadata/newMetadata.csv", na.strings = "") %>%
  .[, DATE := as.ordered(format(as.Date(DATE, format = "%m/%d/%y")))]
colnames(metadata) <- toupper(colnames(metadata))

tmp <- 
  grep("OPEN|CLOSE|PRDDT[1-2]{1}|SHWNT[1-2]{1}|FIRET[1-2]{1}|PRDNT[1-2]{1}|SUNSET", 
       colnames(metadata), value = TRUE)
metadata <- metadata[!duplicated(metadata$DATE)]
metadata[, (tmp) := lapply(.SD, as.ITime), .SDcols = tmp]
# which(metadata$MKFIRET1 == metadata$MKFIRET2)
datetime <- 
  data.table("DATE" = rep(metadata$DATE, each = 288), 
             "TIME" = as.ITime(rep(seq(0*3600, 24*3600-1, by = 60*roundTime))))
shows <- grep("PRDDT[1-2]{1}|SHWNT[1-2]{1}|FIRET[1-2]{1}|PRDNT[1-2]{1}", 
              colnames(metadata), value = TRUE)
showType <- c("PRDDT", "SHWNT", "FIRET", "PRDNT")

tmp <- lapply(toupper(unique(dtMeta$PARK)), function(x) {
  type <- grep(paste0(x, showType, collapse = "|"), shows, value = TRUE)
  type <- unique(str_extract(type, paste0(showType, collapse = "|")))
  lapply(type, function(y) {
    cols <- c("DATE", grep(paste0(x, y), shows, value = TRUE))
    y <- melt(metadata[, ..cols],
         measure.vars = cols[-1],
         variable.name = paste0(x, y),
         value.name = paste0(x, y, "TIME"))
    y <- merge(datetime, y,
          by.x = c("DATE", "TIME"),
          by.y = c("DATE", grep("TIME", names(y), value = TRUE)),
          all.x = TRUE)
    y <- y[, !c("DATE", "TIME")]
    return(y)
  })
})
tmp <- rlist::list.cbind(unlist(tmp, recursive = FALSE))
cols <- unique(colnames(tmp))
tmp <- tmp[, ..cols]
tmp <- cbind(datetime, tmp)

cols <- !grepl(paste0(shows, collapse = "|"), colnames(metadata))
metadata <- merge(tmp, metadata[, ..cols], all.x = TRUE, by = "DATE")

metadata <- metadata[TIME >= as.ITime("06:00:00") | 
                       TIME <= as.ITime("03:00:00")]

tmp <- merge(dt, metadata, by = c("DATE", "TIME"), all.y = TRUE) %>%
  .[, `:=`(YEAR = NULL, MONTH = NULL, DAY = NULL)]
dt <- tmp
rm(tmp)
rm(metadata)
```

## Add in the weather data 

```{r}
nc <- tidync("data/w2012_2018.nc")
w2012_2018 <- nc %>%
  hyper_tibble() %>%
  data.table() %>%
  .[, `:=`(TIME = as.POSIXct(time * 60 * 60,
                             origin = "1900/01/01", tz = "EST"),
           temp = ((t2m - 273.15) * 9/5) + 32,
           rain = tp,
           longitude = NULL, latitude = NULL,
           t2m = NULL, tp = NULL, time = NULL)] %>%
  .[, `:=`(DATE = as.ordered(as.Date(TIME, format = "%m/%d/%y", tz = "EST")),
           hour = hour(as.ITime(TIME)),
           TIME = NULL)]

nc <- tidync("data/w2019_2021.nc")
w2019_2021 <- nc %>%
  hyper_tibble() %>%
  data.table() %>%
  .[, `:=`(TIME = as.POSIXct(time * 60 * 60, 
                             origin = "1900/01/01", tz = "EST"),
           temp = ((t2m - 273.15) * 9/5) + 32,
           rain = tp,
           longitude = NULL, latitude = NULL, 
           t2m = NULL, tp = NULL, time = NULL)] %>%
  .[, `:=`(DATE = as.ordered(as.Date(TIME, format = "%m/%d/%y", tz = "EST")),
           hour = hour(as.ITime(TIME)),
           TIME = NULL)]

w2019_2021 <- rbind(w2012_2018, w2019_2021)

# w2019_2021 <- w2019_2021 %>%
#   .[, `:=`(hour = hour(TIME), TIME = NULL)]

nc <- merge(datetime[, `:=`(hour = hour(TIME))], 
            w2019_2021, by = c("DATE", "hour"), all.x = TRUE) %>%
  .[, hour := NULL] %>%
  .[rowSums(is.na(.)) == 0]

dt <- merge(dt, nc, by = c("DATE", "TIME"), all.x = TRUE) %>%
  .[, DATE := as.ordered(format(as.Date(DATE), format = "%m-%d"))]

cols <- grep("CLOSED", colnames(dt), value = TRUE)
dt[, (cols) := lapply(.SD, function(x) { 
  as.logical(case_when(
    is.na(x) ~ FALSE,
    x == 0 ~ FALSE,
    TRUE ~ TRUE
  )) 
  }), .SDcols = cols]

rm("datetime", "files", "nc", "w2012_2018", "w2019_2021")
```

```{r}
# saveRDS(dt, "BIG_DATA.rds")
# dt <- readRDS("BIG_DATA.rds")
```


## Lag the data

```{r}
# lag the actual data
cols <- paste0(dtMeta$RIDENAME, c("_SACTMIN"))
dt <- dt[, (cols) :=  shift(.SD, n = 1, type = "lead"), 
         by = .(DATE), .SDcols = cols]
```

## Split the data

```{r}
set.seed(2022)
rowPicker <- sample(c(TRUE, FALSE), nrow(dt), replace = TRUE, prob = c(.8, .2))

cols <- sapply(dt, function(x) { is.factor(x) | is.character(x) })
cols <- names(cols)[cols == TRUE & names(cols) != "DATE"]

dt2 <- dt
dt2 <- dt2[, (cols) := lapply(.SD, function(x = .SD, y = names(.SD)) {
  factor(x, levels = unique(x))
}), .SDcols = cols]

train <- dt2[rowPicker]
train[, TIME := as.numeric(as.numeric(TIME)  / 3600)]

test <- dt2[rowPicker]
test[, TIME := as.numeric(as.numeric(TIME)  / 3600)]

colnames(train) <- toupper(colnames(train))
colnames(test) <- toupper(colnames(test))
```

## Create the trees

```{r, out.width="1920px", out.height="1080px"}
cat("", file = "trees.txt")
tr <- rbindlist(lapply(unique(dtMeta$PARK), function(x) {
  # get columns for the park
  # drop the columns for rides not in the park
  rides <-
    colnames(train)[!grepl(paste0(unique(dtMeta$PARK[!dtMeta$PARK %in% x]), 
                                  collapse = "|"), colnames(train))]
  rides <- rides[!grepl(paste0(dtMeta$RIDENAME[dtMeta$PARK != x], 
                               collapse = "|"), rides)]
  # get the actual ride time variables
  actuals <- rides[grepl("(SACTMIN)", rides)]
  # return decision trees for the actual ride time variables
  return(rbindlist(lapply(actuals, function(y) {
    tr <- rpart(as.formula(paste(y, "~ .")), train[, ..rides])
    cat(paste0(y, "\n"), file = "trees.txt", append = TRUE)
    sink("trees.txt", append = TRUE); print(tr); sink()
    cat("\n\n", file = "trees.txt", append = TRUE)
    rpart.plot(tr, main = y)
    pred <- predict(tr, test)
    tmp <- data.table("actual" = test[[y]], "predicted" = pred)
    tmp <- tmp[!is.na(tmp$actual)][, `:=`(lower = actual * .85,
                                          upper = actual * 1.15)]
    tmp[, within := 
          ifelse(predicted >= lower & predicted <= upper, TRUE, FALSE)]
    tmpTbl <- table(tmp$within)
    tr <- data.table("ride" = y,
                     "mse" = mean((pred - test[[y]])^2, na.rm = TRUE),
                     "accuracy" = tmpTbl["TRUE"] / sum(tmpTbl),
                     "error" = mean(ifelse(test[[y]] - pred > 0, 1, 0), 
                                    na.rm = TRUE),
                     "time" = mean(test[[y]], na.rm = TRUE),
                     "lower" = mean(tmp$lower),
                     "upper" = mean(tmp$upper))
    return(tr)
    })))
}))
tr[order(-accuracy),]
fwrite(tr, "accuracy.csv")
mean(tr$accuracy)

# Histogram
hist(tr$accuracy, prob = TRUE,
     col = "grey",
     main = "", xlab = "", ylab = "",
     xlim = c(0, .5))
par(new = TRUE)
boxplot(tr$accuracy, horizontal = TRUE, axes = FALSE,
        ylim = c(0, .5),
        col = rgb(0, 0.8, 1, alpha = 0.5),
        xlab = "Accuracy", ylab = "Count",
        main = "Distribution of levels of model accuracy")
box()
```

